{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybrain.datasets            import ClassificationDataSet\n",
      "from pybrain.utilities           import percentError\n",
      "from pybrain.tools.shortcuts     import buildNetwork\n",
      "from pybrain.supervised.trainers import BackpropTrainer\n",
      "from pybrain.structure.modules   import SoftmaxLayer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylab import ion, ioff, figure, draw, contourf, clf, show, hold, plot\n",
      "from scipy import diag, arange, meshgrid, where\n",
      "from numpy.random import multivariate_normal"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "means = [(-1,0),(2,4),(3,1)]\n",
      "cov = [diag([1,1]), diag([0.5,1.2]), diag([1.5,0.7])]\n",
      "alldata = ClassificationDataSet(2, 1, nb_classes=3)\n",
      "for n in xrange(400):\n",
      "    for klass in range(3):\n",
      "        input = multivariate_normal(means[klass],cov[klass])\n",
      "        alldata.addSample(input, [klass])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print alldata.data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'input': array([[-1.84948711,  0.028358  ],\n",
        "       [ 2.26917096,  4.62360503],\n",
        "       [ 1.55389097,  0.90155978],\n",
        "       ..., \n",
        "       [ 0.86133505,  2.02790068],\n",
        "       [-1.84948711,  0.028358  ],\n",
        "       [ 2.26917096,  4.62360503]]), 'target': array([[0],\n",
        "       [1],\n",
        "       [2],\n",
        "       ..., \n",
        "       [1],\n",
        "       [0],\n",
        "       [1]]), 'class': array([], shape=(0, 1), dtype=int64)}\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dir(alldata)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['_DataSet__vectorformat', '__add__', '__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__getitem__', '__hash__', '__init__', '__iter__', '__len__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_appendUnlinked', '_convert', '_convertArray1d', '_convertArray2d', '_convertList', '_convertToClassNb', '_convertToOneOfMany', '_evaluateSequence', '_provideSequences', '_resize', '_resizeArray', 'addField', 'addSample', 'append', 'appendLinked', 'assignClasses', 'batches', 'calculateStatistics', 'castToRegression', 'class_labels', 'clear', 'convertField', 'copy', 'data', 'endOfData', 'endmarker', 'evaluateMSE', 'evaluateModuleMSE', 'getClass', 'getDimension', 'getField', 'getFieldNames', 'getLength', 'getLinked', 'getSample', 'getVectorFormat', 'hasField', 'index', 'indim', 'link', 'linkFields', 'loadFromFile', 'loadFromFileLike', 'load_libsvm', 'load_matlab', 'load_pickle', 'nClasses', 'outdim', 'randomBatches', 'reconstruct', 'replaceNansByMeans', 'reset', 'saveToFile', 'saveToFileLike', 'save_pickle', 'setField', 'setVectorFormat', 'splitByClass', 'splitWithProportion', 'unlinkFields', 'vectorformat']\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alldata._convertToOneOfMany()\n",
      "tstdata, trndata = alldata.splitWithProportion( 0.25 )\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dir(trndata)\n",
      "trndata.getField('class')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'class'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-28-cc1eb264b354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrndata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/PyBrain-0.3.3-py2.7.egg/pybrain/datasets/dataset.pyc\u001b[0m in \u001b[0;36mgetField\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# Note: label_data should always be a np.array, so this will never\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;31m# actually clone a list (performances are O(1)).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mlabel_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendmarker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Convert to list if requested.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: 'class'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['_DataSet__vectorformat', '__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__getitem__', '__hash__', '__init__', '__iter__', '__len__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_appendUnlinked', '_convert', '_convertArray1d', '_convertArray2d', '_convertList', '_evaluateSequence', '_provideSequences', '_resize', '_resizeArray', 'addField', 'addSample', 'append', 'appendLinked', 'batches', 'clear', 'convertField', 'copy', 'data', 'endOfData', 'endmarker', 'evaluateMSE', 'evaluateModuleMSE', 'getDimension', 'getField', 'getFieldNames', 'getLength', 'getLinked', 'getSample', 'getVectorFormat', 'hasField', 'index', 'indim', 'link', 'linkFields', 'loadFromFile', 'loadFromFileLike', 'load_pickle', 'outdim', 'randomBatches', 'reconstruct', 'replaceNansByMeans', 'reset', 'saveToFile', 'saveToFileLike', 'save_pickle', 'setField', 'setVectorFormat', 'splitWithProportion', 'unlinkFields', 'vectorformat']\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "print \"Number of training patterns: \", len(trndata)\n",
      "print \"Input and output dimensions: \", trndata.indim, trndata.outdim\n",
      "print \"First sample (input, target, class):\"\n",
      "print trndata['input'][0], trndata['target'][0]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of training patterns:  900\n",
        "Input and output dimensions:  2 3\n",
        "First sample (input, target, class):\n",
        "[ 2.0121398   0.21661277] [0 0 1]\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fnn = buildNetwork( trndata.indim, 5, trndata.outdim, outclass=SoftmaxLayer )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer = BackpropTrainer( fnn, dataset=trndata, momentum=0.1, verbose=True, weightdecay=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ticks = arange(-3.,6.,0.2)\n",
      "X, Y = meshgrid(ticks, ticks)\n",
      "# need column vectors in dataset, not arrays\n",
      "griddata = ClassificationDataSet(2,1, nb_classes=3)\n",
      "for i in xrange(X.size):\n",
      "    griddata.addSample([X.ravel()[i],Y.ravel()[i]], [0])\n",
      "griddata._convertToOneOfMany()  # this is still needed to make the fnn feel comfy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(20):"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}