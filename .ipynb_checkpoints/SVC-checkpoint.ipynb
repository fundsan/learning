{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "from sklearn.externals.six.moves import zip\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.datasets import make_gaussian_quantiles\n",
      "from sklearn import svm\n",
      "from sklearn.metrics import accuracy_score\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn as sk\n",
      "from sklearn import preprocessing\n",
      "from sklearn.externals.six.moves import zip\n",
      "\n",
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "\n",
      "coveragedata = pd.read_csv('foresttrain.csv', header= 0) \n",
      "coveragedata.drop('Id', axis = 1)\n",
      "connectdata = pd.read_csv('connect-4.csv', header= None) \n",
      "\n",
      "def splitColumns(dataset):\n",
      "    columns = []\n",
      "    binar = []\n",
      "    for key in dataset.columns:\n",
      "    \n",
      "        if len(dataset[key].groupby(dataset[key]).groups.keys()) >2:\n",
      "            columns.append(key)\n",
      "            \n",
      "        else:\n",
      "            binar.append(key)\n",
      "    return columns, binar\n",
      "connectCol, _ = splitColumns(connectdata)\n",
      "connectCol.remove(len(connectdata.columns)-1)\n",
      "from sklearn.feature_extraction import DictVectorizer\n",
      "\n",
      "def hot_dataframe(data, cols, replace=False):\n",
      "    \"\"\" \n",
      "    Modified from https://gist.github.com/kljensen/5452382\n",
      "    \"\"\"\n",
      "    vec = DictVectorizer()\n",
      "    #mkdict = lambda row: dict((col, row[col]) for col in cols)\n",
      "    collist = [column for column in cols.columns]\n",
      "    vecData = pd.DataFrame(vec.fit_transform(cols.to_dict(outtype='records')).toarray())\n",
      "    vecData.columns = vec.get_feature_names()\n",
      "    vecData.index = data.index\n",
      "    \n",
      "    if replace is True:\n",
      "        \n",
      "        data = data.drop(collist, axis=1)\n",
      "        data = data.join(vecData)\n",
      "    \n",
      "    return data, vecData\n",
      "\n",
      "connectdata, _ = hot_dataframe(connectdata,connectdata[connectCol],replace=True)\n",
      "\n",
      "\n",
      "\n",
      "def labelEncode(data, col, uni = False):\n",
      "    if uni == True:\n",
      "        if isinstance(col, pd.DataFrame):\n",
      "            collist = [column for column in col.columns]\n",
      "        else:\n",
      "            collist = [col.name]\n",
      "    else:\n",
      "        collist = col\n",
      "    le = preprocessing.LabelEncoder()\n",
      "    for column in collist:\n",
      "        data[column] = le.fit_transform(data[column])\n",
      "    return data\n",
      "connectdata = labelEncode( connectdata, connectdata[42],True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import *\n",
      "def get_important_features(max_importance, columns, importances):\n",
      "    sorted_importances = list(np.sort(importances))\n",
      "    important_features = []\n",
      "    total = 0.0\n",
      "    while total <= max_importance and total < 1. and sorted_importances is not None:\n",
      "        current = sorted_importances.pop()\n",
      "        ind = importances.index(current)\n",
      "        \n",
      "        if total + current > max_importance:\n",
      "            return important_features\n",
      "        else:\n",
      "            important_features.append(columns[ind])\n",
      "            total += current\n",
      "    return important_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "connect_train, connect_test = train_test_split(connectdata,test_size = .5, random_state= 21)\n",
      "\n",
      "\n",
      "\n",
      "decConnect = DecisionTreeClassifier()\n",
      "decConnect.fit(connect_train[:,1:], connect_train[:,0])\n",
      "gini_val = list(decConnect.feature_importances_)\n",
      "features = connectdata.columns \n",
      "imp = get_important_features(.3, features, gini_val)\n",
      "imp.insert(0,42)\n",
      "connectdata = connectdata[imp]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coverage_train, coverage_test = train_test_split(coveragedata,test_size = .5, random_state= 21)\n",
      "\n",
      "\n",
      "\n",
      "decCoverage = DecisionTreeClassifier()\n",
      "decCoverage.fit(coverage_train[:,:coverage_train.shape[1]-1], coverage_train[:,coverage_train.shape[1]-1])\n",
      "gini_val = list(decCoverage.feature_importances_)\n",
      "features = coveragedata.columns \n",
      "imp = get_important_features(.70, features, gini_val)\n",
      "imp.insert(0,u'Cover_Type')\n",
      "coveragedata=coveragedata[imp]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "connect_train, connect_test = train_test_split(connectdata,test_size = .5, random_state = 21)\n",
      "coverage_train, coverage_test = train_test_split(coveragedata,test_size = .5, random_state = 21)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connect_test_errors = []\n",
      "connect_training_errors = []\n",
      "\n",
      "connect_train, connect_test = train_test_split(connectdata,test_size = .5, random_state = 21)\n",
      "\n",
      "for time in range(10):\n",
      "    print time\n",
      "    clfConnect = svm.SVC(cache_size= 700)\n",
      "    clfConnect.fit(connect_train[:,1:], connect_train[:,0])\n",
      "\n",
      "    connect_training_errors.append(1. - accuracy_score(connect_train[:,0], clfConnect.predict(connect_train[:,1:])))\n",
      "\n",
      "    connect_test_errors.append(1. - accuracy_score(connect_test[:,0], clfConnect.predict(connect_test[:,1:])))\n",
      "    connect_train, _ = train_test_split(connect_train,test_size = .2, random_state = 21)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "connect_test_errors_linear = []\n",
      "connect_training_errors_linear = []\n",
      "connect_Ms = []\n",
      "connect_train, connect_test = train_test_split(connectdata,test_size = .5, random_state = 21)\n",
      "\n",
      "for time in range(10):\n",
      "    connect_Ms.append(len(connect_train))\n",
      "    print time\n",
      "    clfConnect = svm.SVC(kernel = 'linear',cache_size= 700 )\n",
      "    clfConnect.fit(connect_train[:,1:], connect_train[:,0])\n",
      "\n",
      "    connect_training_errors_linear.append(1. - accuracy_score(connect_train[:,0], clfConnect.predict(connect_train[:,1:])))\n",
      "\n",
      "    connect_test_errors_linear.append(1. - accuracy_score(connect_test[:,0], clfConnect.predict(connect_test[:,1:])))\n",
      "    connect_train, _ = train_test_split(connect_train,test_size = .2, random_state = 21)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clfConnect.intercept_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([-1.00002655, -1.00009645, -0.99997961])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(1)\n",
      "\n",
      "plt.plot(connect_Ms,connect_test_errors , 'k', c='green', label='Testing Error  kernel:rbf')\n",
      "plt.plot(connect_Ms,connect_training_errors , 'k', c='purple', label='Training Error kernel:rbf')\n",
      "plt.plot(connect_Ms,connect_test_errors_linear , 'k', c='blue', label='Testing Error kernel: linear')\n",
      "plt.plot(connect_Ms,connect_training_errors_linear , 'k', c='red', label='Training error kernel:linear')\n",
      "plt.legend(bbox_to_anchor=(.65, .3), loc=2, borderaxespad=0.)\n",
      "plt.plot(connect_Ms,connect_test_errors , 'bo',c='green')\n",
      "plt.plot(connect_Ms,connect_training_errors, 'bo', c='purple')\n",
      "plt.plot(connect_Ms,connect_test_errors_linear , 'bo',c='blue')\n",
      "plt.plot(connect_Ms,connect_training_errors_linear, 'bo', c='red')\n",
      "plt.ylabel('Standard Error')\n",
      "plt.xlabel('Number of Instances For Training Set')\n",
      "plt.title('Hypothesis Errors for Connect 4 Data for SVC')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coverage_test_errors = []\n",
      "coverage_training_errors = []\n",
      "coverage_train, coverage_test = train_test_split(coveragedata,test_size = .5, random_state = 21)\n",
      "coverage_Ms = []\n",
      "\n",
      "for time in range(10):\n",
      "    print time\n",
      "    coverage_Ms.append(len(coverage_train))\n",
      "    clfCoverage = svm.SVC(cache_size = 700)\n",
      "    clfCoverage.fit(coverage_train[:,1:], coverage_train[:,0])\n",
      "\n",
      "    coverage_training_errors.append(1. - accuracy_score(coverage_train[:,0] ,\n",
      "                                                        clfCoverage.predict(coverage_train[:,1:])))\n",
      "    coverage_test_errors.append(1. - accuracy_score(coverage_test[:,0],\n",
      "                                                    clfCoverage.predict(coverage_test[:,1:])))\n",
      "\n",
      "    coverage_train, _ = train_test_split(coverage_train,test_size = .2, random_state = 21)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coverage_test_errors_linear = []\n",
      "coverage_training_errors_linear = []\n",
      "coverage_train, coverage_test = train_test_split(coveragedata,test_size = .5, random_state = 21)\n",
      "coverage_Ms = []\n",
      "\n",
      "for time in range(10):\n",
      "    print time\n",
      "    coverage_Ms.append(len(coverage_train))\n",
      "    clfCoverage = svm.SVC(kernel= 'linear',cache_size=700)\n",
      "    clfCoverage.fit(coverage_train[:,1:], coverage_train[:,0])\n",
      "\n",
      "    coverage_training_errors_linear.append(1. - accuracy_score(coverage_train[:,0] ,\n",
      "                                                        clfCoverage.predict(coverage_train[:,1:])))\n",
      "    coverage_test_errors_linear.append(1. - accuracy_score(coverage_test[:,0],\n",
      "                                                    clfCoverage.predict(coverage_test[:,1:])))\n",
      "\n",
      "    coverage_train, _ = train_test_split(coverage_train,test_size = .2, random_state = 21)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coverage_test_errors_poly = []\n",
      "coverage_training_errors_poly = []\n",
      "coverage_train, coverage_test = train_test_split(coveragedata,test_size = .5, random_state = 21)\n",
      "coverage_Ms = []\n",
      "\n",
      "for time in range(10):\n",
      "    print time\n",
      "    coverage_Ms.append(len(coverage_training))\n",
      "    clfCoverage = svm.SVC(kernel= 'poly')\n",
      "    clfCoverage.fit(coverage_train[:,1:], coverage_train[:,0])\n",
      "\n",
      "    coverage_training_errors_poly.append(1. - accuracy_score(coverage_train[:,0] ,\n",
      "                                                        clfCoverage.predict(coverage_train[:,1:])))\n",
      "    coverage_test_errors_poly.append(1. - accuracy_score(coverage_test[:,0],\n",
      "                                                    clfCoverage.predict(coverage_test[:,1:])))\n",
      "\n",
      "    coverage_train, _ = train_test_split(coverage_training,test_size = .2, random_state = 21)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}